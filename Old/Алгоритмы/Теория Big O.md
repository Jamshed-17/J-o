#Программирование 

**Big O** - это термин из мира анализа алгоритмов. Он нужен для оценки временных затрат алгоритма. 

### Примеры нотаций Big O

- **O(1):** **Константная сложность**. Время выполнения алгоритма не зависит от размера входных данных. Например, доступ к элементу массива по индексу.
    
- **O(log n)**: **Логарифмическая сложность**. Время выполнения алгоритма растет медленно с увеличением размера входных данных. Например, бинарный поиск в отсортированном массиве.
    
- **O(n)**: **Линейная сложность**. Время выполнения алгоритма пропорционально размеру входных данных. Например, просмотр всех элементов в массиве.
    
- **O(n log n)**: **Линейно-логарифмическая сложность**. Время выполнения алгоритма растет быстрее, чем линейно, но медленнее, чем квадратично. Например, сортировка слиянием (merge sort).
    
- **O(n^2)**: **Квадратичная сложность**. Время выполнения алгоритма зависит от квадрата размера входных данных. Например, сортировка пузырьком (bubble sort).
    
- **O(n^3):** **Кубическая сложность**. Время выполнения алгоритма зависит от размера входных данных в кубе. Например, алгоритмы, которые имеют три вложенных цикла, такие как некоторые методы многомерной обработки данных.
    
- **O(n!):** **Факториальная сложность**. Это самая высокая степень роста времени выполнения алгоритма. Время выполнения алгоритма растет факториально от размера входных данных. Этот тип сложности встречается, например, при переборе всех возможных комбинаций элементов, что делает его чрезвычайно неэффективным для больших значений **n**.

> [!NOTE]
> ## Другие обозначения сложности алгоритмов.
> 
> Кроме обозначения "**Big O"**, существуют другие обозначения для оценки сложности алгоритмов.
> 
> Вот несколько наиболее распространенных обозначений:
> 
> 1. **Big Theta (Θ)**: Big Theta также оценивает верхнюю и нижнюю границы временной сложности алгоритма, но описывает точную сложность, а не только наихудший случай, как Big O. Θ(f(n)) обозначает, что время выполнения алгоритма ограничено функцией f(n) как сверху, так и снизу.
>     
> 2. **Big Omega (Ω)**: Big Omega оценивает нижнюю границу временной сложности алгоритма. Ω(f(n)) говорит о том, что алгоритм выполнится не быстрее, чем функция f(n).
>     
> 3. **Little O (o)**: Little O представляет собой верхнюю границу, которая строже, чем Big O. Если f(n) является o(g(n)), это означает, что время выполнения алгоритма ограничивается функцией g(n), но алгоритм работает быстрее, чем g(n).
>     
> 4. **Little Omega (ω)**: Little Omega представляет собой нижнюю границу, которая строже, чем Big Omega. Если f(n) является ω(g(n)), это означает, что алгоритм работает медленнее, чем g(n), но не медленнее, чем f(n).

График сложностей Big O:
[![image.png](https://i.postimg.cc/P5jsthP1/image.png)](https://postimg.cc/zV0Pjswf)

