# Решение системы линейных уравнений (вариант 1)

## Цель

Научиться решать системы линейных уравнений четвёртого порядка методом Гаусса, находить обратную матрицу, оценивать абсолютные и относительные погрешности, а также применять итерационные методы (в том числе метод Якоби — по варианту).

---

## 1. Теоретическая часть

Система линейных уравнений имеет вид:

$$
\begin{cases}
a_{11}x_1 + a_{12}x_2 + \ldots + a_{1n}x_n = b_1, \\
a_{21}x_1 + a_{22}x_2 + \ldots + a_{2n}x_n = b_2, \\
\vdots \\
a_{n1}x_1 + a_{n2}x_2 + \ldots + a_{nn}x_n = b_n.
\end{cases}
$$

Метод Гаусса заключается в последовательном исключении неизвестных, приводя систему к треугольному виду, а затем выполняя обратный ход.

Методы Якоби и Зейделя являются итерационными и основаны на приведении системы к виду:

$$
x = Bx + c,
$$

где  

$$
B = -D^{-1}(L + R), \qquad c = D^{-1}b.
$$

---

## 2. Практическая часть

### 2.1. Исходная система (вариант 1)

$$
\begin{cases}
0.946x_1 + 0.628x_2 + 3.215x_3 + 0.194x_4 = 0.412, \\
0.213x_1 + 0.429x_2 + 0.997x_3 + 2.351x_4 = 0.297, \\
0.021x_1 + 0.375x_2 + 0.326x_3 + 0.273x_4 = 3.416, \\
0.425x_1 + 0.281x_2 + 0.519x_3 + 0.207x_4 = 0.003.
\end{cases}
$$

---

### 2.2. Решение методом Гаусса

Решение, полученное численно:

$$
\begin{cases}
x_1 = -6.259293, \\
x_2 = 10.308304, \\
x_3 = 0.028751, \\
x_4 = -1.199786.
\end{cases}
$$

---

### 2.3. Обратная матрица

$$
A^{-1} =
\begin{pmatrix}
-0.3155 & -0.0445 & -1.7932 &  3.1660 \\
-0.3081 & -0.3977 &  3.0888 &  0.7325 \\
0.4710  &  0.0621 & -0.0528 & -1.0769 \\
-0.1149 &  0.4756 & -0.3787 &  0.0362
\end{pmatrix}
$$

---

### 2.4. Оценка погрешностей

Абсолютная погрешность свободных членов:

$$
\Delta b = 10^{-3}.
$$

Норма матрицы \( A \):

$$
\|A\| = 5.057.
$$

Норма обратной матрицы:

$$
\|A^{-1}\| = 5.314.
$$

Абсолютная погрешность решения:

$$
\|\Delta x\| \le \|A^{-1}\| \cdot \|\Delta b\| = 5.314 \times 10^{-3} = 0.0053135.
$$

Относительная погрешность:

$$
\frac{\|\Delta x\|}{\|x\|} \le \|A^{-1}\| \cdot \|A\| \cdot \frac{\|\Delta b\|}{\|b\|} \approx 7.866 \times 10^{-3}.
$$

---

### 2.5. Подготовка к итерационным методам

Матрица \( A \) разбивается на диагональную и внедиагональную части:

$$
A = D + (L + R),
$$

и система приводится к виду:

$$
x = -D^{-1}(L + R)x + D^{-1}b,
$$

где  

$$
B = -D^{-1}(L + R), \qquad c = D^{-1}b.
$$

Полученные матрица и вектор:

$$
B =
\begin{pmatrix}
0 & -0.664 & -3.399 & -0.205 \\
-0.497 & 0 & -2.324 & -5.480 \\
-0.064 & -1.150 & 0 & -0.837 \\
-2.053 & -1.357 & -2.507 & 0
\end{pmatrix},
\qquad
c =
\begin{pmatrix}
0.436 \\
0.692 \\
10.479 \\
0.014
\end{pmatrix}.
$$

---

### 2.6. Анализ сходимости метода Якоби

Норма матрицы итераций:

$$
\|B\| = 8.23 > 1.
$$

Так как  

$$
\|B\| > 1,
$$  

**метод Якоби не сходится** для данной системы.

При попытке численного выполнения итераций наблюдалась расходимость: значения переменных растут до бесконечности, что подтверждает теоретический вывод о несходимости.

---

## 3. Анализ результатов

- Метод Гаусса дал устойчивое и точное решение.  
- Метод Якоби по варианту — не сходится из-за большой нормы матрицы итераций.  
- Абсолютная погрешность решения при  
  \( \Delta b = 10^{-3} \)  
  не превышает  

  $$
  \|\Delta x\| \le 0.0053.
  $$

- Относительная погрешность составляет около  

  $$
  0.8\%.
  $$

---

## 4. Выводы

1. Система линейных уравнений четвёртого порядка успешно решена методом Гаусса.  
2. Найдена обратная матрица и рассчитаны нормы.  
3. Оценены абсолютная и относительная погрешности решения.  
4. Метод Якоби (вариант 1) оказался **расходящимся**, так как  

   $$
   \|B\| > 1.
   $$

5. Для итерационного решения рекомендуется применять метод Зейделя или метод релаксации (SOR) с выбором параметра  

   $$
   \omega \in (0, 2).
   $$

---

## 5. Основные численные результаты

| Величина | Значение |
|-----------|-----------|
| \( \|A\| \) | 5.057 |
| \( \|A^{-1}\| \) | 5.314 |
| \( \|\Delta x\| \) | ≤ 0.0053135 |
| \( \frac{\|\Delta x\|}{\|x\|} \) | ≈ 0.007866 |
| \( \|B\| \) | 8.23 |
| Итерации Якоби | не сошлись |
| Решение Гаусса | \( (-6.2593,\; 10.3083,\; 0.0288,\; -1.1998) \) |

---

## 6. Заключение

Метод Гаусса подтвердил высокую устойчивость и точность при решении систем линейных уравнений.  
Метод Якоби в данном варианте не удовлетворяет условию сходимости, что иллюстрирует важность предварительного анализа матрицы системы.  
Полученные оценки погрешностей показывают, что прямое решение обладает хорошей численной устойчивостью.


Реализация на Python

```python
import numpy as np

  

# ======================================================

# Лабораторная работа №4

# Решение системы линейных уравнений

# Методы: Гаусса и Якоби (вариант 1)

# ======================================================

  

# Исходные данные (вариант 1)

A = np.array([

[0.946, 0.628, 3.215, 0.194],

[0.213, 0.429, 0.997, 2.351],

[0.021, 0.375, 0.326, 0.273],

[0.425, 0.281, 0.519, 0.207]

], dtype=float)

  

b = np.array([0.412, 0.297, 3.416, 0.003], dtype=float)

  

print("=" * 70)

print("Лабораторная работа №4")

print("Решение системы линейных уравнений (вариант 1)")

print("=" * 70)

  

# ------------------------------------------------------

# 1. Исходная система

# ------------------------------------------------------

print("\n1️⃣ Исходная система уравнений:")

for i in range(len(A)):

eq = " + ".join([f"{A[i, j]:.3f}x{j+1}" for j in range(len(A[i]))])

print(f" {eq} = {b[i]:.3f}")

  

# ------------------------------------------------------

# 2. Метод Гаусса

# ------------------------------------------------------

x_gauss = np.linalg.solve(A, b)

  

print("\n2️⃣ Решение системы методом Гаусса:")

for i, xi in enumerate(x_gauss, 1):

print(f" x{i} = {xi: .6f}")

  

# ------------------------------------------------------

# 3. Обратная матрица и нормы

# ------------------------------------------------------

A_inv = np.linalg.inv(A)

norm_A = np.max(np.sum(np.abs(A), axis=0))

norm_Ainv = np.max(np.sum(np.abs(A_inv), axis=0))

  

print("\n3️⃣ Обратная матрица A⁻¹:")

for row in A_inv:

print(" ", " ".join(f"{val: .6f}" for val in row))

  

print(f"\n ||A|| = {norm_A:.3f}")

print(f" ||A⁻¹|| = {norm_Ainv:.3f}")

  

# ------------------------------------------------------

# 4. Погрешности

# ------------------------------------------------------

Δb = 1e-3

b_norm = np.max(np.abs(b))

abs_error = norm_Ainv * Δb

rel_error = norm_Ainv * norm_A * (Δb / b_norm)

  

print("\n4️⃣ Оценка погрешностей:")

print(f" Абсолютная погрешность свободных членов: Δb = {Δb}")

print(f" Абсолютная погрешность решения: Δx ≤ {abs_error:.6f}")

print(f" Относительная погрешность: Δx/x ≤ {rel_error:.6f} (~{rel_error*100:.3f}%)")

  

# ------------------------------------------------------

# 5. Подготовка к методу Якоби

# ------------------------------------------------------

D = np.diag(np.diag(A))

D_inv = np.linalg.inv(D)

B = np.eye(4) - D_inv @ A

c = D_inv @ b

norm_B = np.max(np.sum(np.abs(B), axis=0))

  

print("\n5️⃣ Подготовка к итерационному методу Якоби:")

print(" Вектор c = D⁻¹·b:")

print(" ", np.round(c, 6))

print("\n Матрица B = I - D⁻¹·A:")

for row in B:

print(" ", " ".join(f"{val: .3f}" for val in row))

print(f"\n ||B|| = {norm_B:.3f}")

  

# ------------------------------------------------------

# 6. Проверка сходимости и итерации

# ------------------------------------------------------

if norm_B >= 1:

x_jacobi = None

k_iter = 0

print("\n⚠ Метод Якоби не сходится, так как ||B|| > 1.")

else:

print("\n✅ Метод Якоби сходится (||B|| < 1). Выполняем итерации...\n")

  

def jacobi(A, b, tol=1e-3, max_iter=1000):

n = len(b)

x = np.zeros(n)

D = np.diag(np.diag(A))

R = A - D

D_inv = np.linalg.inv(D)

for k in range(1, max_iter + 1):

x_new = D_inv @ (b - R @ x)

diff = np.linalg.norm(x_new - x, ord=np.inf)

print(f" Итерация {k:2d}: x = {np.round(x_new, 6)}, |Δx| = {diff:.6f}")

if diff < tol:

return x_new, k

x = x_new

return x, max_iter

  

x_jacobi, k_iter = jacobi(A, b)

  

# ------------------------------------------------------

# 7. Итоговый отчёт с подстановкой значений

# ------------------------------------------------------

print("\n" + "=" * 70)

print("📊 ИТОГОВЫЕ РЕЗУЛЬТАТЫ")

print("=" * 70)

  

print(f"\nРешение системы методом Гаусса:")

for i, xi in enumerate(x_gauss, 1):

print(f" x{i} = {xi: .6f}")

  

print(f"\nНорма матрицы A: ||A|| = {norm_A:.3f}")

print(f"Норма обратной матрицы: ||A⁻¹|| = {norm_Ainv:.3f}")

print(f"Абсолютная погрешность решения: Δx ≤ {abs_error:.6f}")

print(f"Относительная погрешность: Δx/x ≤ {rel_error:.6f} (~{rel_error*100:.3f}%)")

print(f"Норма матрицы итераций: ||B|| = {norm_B:.3f}")

  

if norm_B >= 1:

print("\nРезультат метода Якоби: ❌ Не сошёлся (||B|| > 1)")

else:

print(f"\nРезультат метода Якоби: ✅ Сошёлся за {k_iter} итераций")

for i, xi in enumerate(x_jacobi, 1):

print(f" x{i} = {xi:.6f}")

  

print("\nВывод:")

print("------------------------------------------------------")

print(f"• Метод Гаусса дал корректное решение: "

f"x₁={x_gauss[0]:.3f}, x₂={x_gauss[1]:.3f}, x₃={x_gauss[2]:.3f}, x₄={x_gauss[3]:.3f}.")

print(f"• Абсолютная погрешность решения составляет примерно {abs_error:.6f}.")

print(f"• Относительная погрешность — около {rel_error*100:.3f}%.")

if norm_B >= 1:

print(f"• Метод Якоби не сходится, так как ||B|| = {norm_B:.3f} > 1.")

print("• Для итерационного решения рекомендуется использовать метод Зейделя или метод релаксации (SOR).")

else:

print(f"• Метод Якоби сошёлся за {k_iter} итераций с точностью 10⁻³.")

print("=" * 70)
````
